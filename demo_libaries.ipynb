{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Conv2d, BatchNorm1d, BatchNorm2d, PReLU, ReLU, ReLU6, Sigmoid, Dropout2d, Dropout, AvgPool2d, MaxPool2d, AdaptiveAvgPool2d, Sequential, Module, Parameter\n",
    "from statistics import mean\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 41\n",
    "# Define custom dataset\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, df, train, num_sample = None, transform = None, num_img_pool = 10, ):\n",
    "        # set random seed for FaceDataset\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        # create constructors\n",
    "        self.unique_img_name = None\n",
    "        self.train = train\n",
    "        self.data = dict()\n",
    "        self.images = list()\n",
    "        self.identities = list()\n",
    "        # label to indices\n",
    "        # self.label_to_indices = dict()\n",
    "        self.labels = list()\n",
    "        self.img_name = list()\n",
    "        # read csv file\n",
    "        self.df = df\n",
    "        # set the transformation\n",
    "        self.transform = transform\n",
    "        # drop last n row from dataframe\n",
    "        self.df = self.df.head(num_sample)\n",
    "        #get the length of entire dataset\n",
    "        self.len_ = len(self.df)\n",
    "        if num_sample is None or num_sample > self.len_:\n",
    "            num_sample = self.len_\n",
    "        # load imgs\n",
    "        self.load_imgs(self.df, num_imgs = num_img_pool, max = num_sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            anchor_img = self.images[idx]\n",
    "            anchor_label = self.labels[idx]\n",
    "            pos_idx = np.random.choice(np.arange(len(self.images))[self.labels == anchor_label])\n",
    "            neg_idx = np.random.choice(np.arange(len(self.images))[self.labels != anchor_label])\n",
    "\n",
    "            pos_img = self.images[pos_idx]\n",
    "            neg_img = self.images[neg_idx]\n",
    "\n",
    "            pos_label = self.labels[pos_idx]\n",
    "            neg_label = self.labels[neg_idx]\n",
    "\n",
    "            if self.transform is None:\n",
    "                img_to_tensor = transforms.ToTensor()\n",
    "                anchor_img = img_to_tensor(anchor_img)\n",
    "                pos_img = img_to_tensor(pos_img)\n",
    "                neg_img = img_to_tensor(neg_img)\n",
    "            else:\n",
    "                anchor_img = self.transform(anchor_img)\n",
    "                pos_img = self.transform(pos_img)\n",
    "                neg_img = self.transform(neg_img)\n",
    "            return anchor_img, pos_img, neg_img\n",
    "\n",
    "        else:\n",
    "            label = False\n",
    "            anchor_img = self.images[idx]\n",
    "            anchor_label = self.labels[idx]\n",
    "            if idx % 2 == 0:\n",
    "                test_idx = np.random.choice(np.arange(len(self.images))[self.labels == anchor_label])\n",
    "                label = True\n",
    "\n",
    "            else:\n",
    "                test_idx = np.random.choice(np.arange(len(self.images))[self.labels != anchor_label])\n",
    "\n",
    "            neg_idx = np.random.choice(np.arange(len(self.images))[self.labels != anchor_label])\n",
    "            test_img = self.images[test_idx]\n",
    "            neg_img = self.images[neg_idx]\n",
    "\n",
    "#             if self.transform is None:\n",
    "#                 img_to_tensor = transforms.ToTensor()\n",
    "#                 anchor_img = img_to_tensor(anchor_img)\n",
    "#                 test_img = img_to_tensor(test_img)\n",
    "#                 neg_img = img_to_tensor(neg_img)\n",
    "\n",
    "#             else:\n",
    "#                 anchor_img = self.transform(anchor_img)\n",
    "#                 test_img = self.transform(test_img)\n",
    "#                 neg_img = self.transform(neg_img)\n",
    "\n",
    "            return anchor_img, test_img, neg_img ,label, self.img_name[test_idx], self.identities[test_idx]\n",
    "\n",
    "    # load imgs from pandas to memory and define the maximum number of images\n",
    "    def load_imgs(self, df, num_imgs, max):\n",
    "        # iterate thought each row\n",
    "        for i, row in tqdm(df.iterrows(), total = max):\n",
    "            # get identity of each row\n",
    "            row_identity = row['identity']\n",
    "            # append each identity to numberical value\n",
    "            # self.label_to_indices[int(row_identity)] = i\n",
    "            count_img = 0\n",
    "            # loop imgs in each identity\n",
    "            for img_name in row['path']:\n",
    "                if count_img > num_imgs:\n",
    "                    break\n",
    "                # concatenate the directoru and image name\n",
    "                # path_to_image = self.dir+img_name\n",
    "                path_to_image = img_name\n",
    "                # open image and convert to RGB\n",
    "#                 img = Image.open(path_to_image).convert('RGB')\n",
    "                self.labels.append(i)\n",
    "                self.images.append(path_to_image)\n",
    "                \n",
    "                self.img_name.append(path_to_image)\n",
    "                self.identities.append(str(row_identity))\n",
    "                \n",
    "                count_img += 1  # print('Added img '+ str(row_identity))\n",
    "        self.labels = np.array(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[digiFace1M\\subjects_0-1999_72_imgs\\0\\20.png, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[digiFace1M\\subjects_0-1999_72_imgs\\1\\66.png, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[digiFace1M\\subjects_0-1999_72_imgs\\2\\29.png, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[digiFace1M\\subjects_0-1999_72_imgs\\3\\42.png, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[digiFace1M\\subjects_0-1999_72_imgs\\4\\33.png, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72661</th>\n",
       "      <td>199994</td>\n",
       "      <td>[digiFace1M\\subjects_166666-199998_5_imgs\\1999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72662</th>\n",
       "      <td>199995</td>\n",
       "      <td>[digiFace1M\\subjects_166666-199998_5_imgs\\1999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72663</th>\n",
       "      <td>199996</td>\n",
       "      <td>[digiFace1M\\subjects_166666-199998_5_imgs\\1999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72664</th>\n",
       "      <td>199997</td>\n",
       "      <td>[digiFace1M\\subjects_166666-199998_5_imgs\\1999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72665</th>\n",
       "      <td>199998</td>\n",
       "      <td>[digiFace1M\\subjects_166666-199998_5_imgs\\1999...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72666 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       identity                                               path\n",
       "0             0  [digiFace1M\\subjects_0-1999_72_imgs\\0\\20.png, ...\n",
       "1             1  [digiFace1M\\subjects_0-1999_72_imgs\\1\\66.png, ...\n",
       "2             2  [digiFace1M\\subjects_0-1999_72_imgs\\2\\29.png, ...\n",
       "3             3  [digiFace1M\\subjects_0-1999_72_imgs\\3\\42.png, ...\n",
       "4             4  [digiFace1M\\subjects_0-1999_72_imgs\\4\\33.png, ...\n",
       "...         ...                                                ...\n",
       "72661    199994  [digiFace1M\\subjects_166666-199998_5_imgs\\1999...\n",
       "72662    199995  [digiFace1M\\subjects_166666-199998_5_imgs\\1999...\n",
       "72663    199996  [digiFace1M\\subjects_166666-199998_5_imgs\\1999...\n",
       "72664    199997  [digiFace1M\\subjects_166666-199998_5_imgs\\1999...\n",
       "72665    199998  [digiFace1M\\subjects_166666-199998_5_imgs\\1999...\n",
       "\n",
       "[72666 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df = pd.read_csv('./digiface_csv_files/digi_all.csv')\n",
    "ds_df = ds_df.groupby('identity')['path'].apply(list).reset_index()\n",
    "ds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 50866\n",
      "Val Size: 13080\n",
      "Test Size: 8720\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26344</th>\n",
       "      <td>120344</td>\n",
       "      <td>[digiFace1M\\subjects_100000-133332_5_imgs\\1203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61833</th>\n",
       "      <td>189166</td>\n",
       "      <td>[digiFace1M\\subjects_166666-199998_5_imgs\\1891...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46921</th>\n",
       "      <td>174254</td>\n",
       "      <td>[digiFace1M\\subjects_166666-199998_5_imgs\\1742...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>8873</td>\n",
       "      <td>[digiFace1M\\subjects_8000-9999_72_imgs\\8873\\54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19875</th>\n",
       "      <td>113875</td>\n",
       "      <td>[digiFace1M\\subjects_100000-133332_5_imgs\\1138...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       identity                                               path\n",
       "26344    120344  [digiFace1M\\subjects_100000-133332_5_imgs\\1203...\n",
       "61833    189166  [digiFace1M\\subjects_166666-199998_5_imgs\\1891...\n",
       "46921    174254  [digiFace1M\\subjects_166666-199998_5_imgs\\1742...\n",
       "4873       8873  [digiFace1M\\subjects_8000-9999_72_imgs\\8873\\54...\n",
       "19875    113875  [digiFace1M\\subjects_100000-133332_5_imgs\\1138..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed = 41\n",
    "# splitting each dataset\n",
    "train_df, eval_df = train_test_split(ds_df, test_size= 0.3, shuffle = True, random_state = seed)\n",
    "val_df, test_df = train_test_split(eval_df, test_size = 0.4, shuffle = True, random_state = seed)\n",
    "\n",
    "# print to check size of each dataset\n",
    "print(f'Train Size: {len(train_df)}')\n",
    "print(f'Val Size: {len(val_df)}')\n",
    "print(f'Test Size: {len(test_df)}')\n",
    "\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b76d9b3a7b4226b97e3d85ce179d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "split = 5\n",
    "k_fold = KFold(n_splits = split, shuffle = True, random_state=seed)\n",
    "\n",
    "val_dataset = FaceDataset(df = test_df, num_sample = 10000, train= False)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n",
    "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\"]\n",
    "\n",
    "result = DeepFace.verify(img1_path = val_df[val_df['identity'] == 100992]['path'].item()[0], img2_path = val_df[val_df['identity'] == 100992]['path'].item()[1], model_name = models[1], distance_metric = metrics[2], enforce_detection=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verified': False,\n",
       " 'distance': 1.0183921163657763,\n",
       " 'threshold': 0.8,\n",
       " 'model': 'Facenet',\n",
       " 'detector_backend': 'opencv',\n",
       " 'similarity_metric': 'euclidean_l2',\n",
       " 'facial_areas': {'img1': {'x': 12, 'y': 17, 'w': 88, 'h': 88},\n",
       "  'img2': {'x': 6, 'y': 16, 'w': 78, 'h': 78}},\n",
       " 'time': 19.03}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a159e5b2edba4b36bc03fa6186a3688b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping fold 1/5\n",
      "skipping fold 2/5\n",
      "skipping fold 3/5\n",
      "starting fold 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88affab1c87043c1b2d030d467172606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19308/4033799982.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0manchor_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_subsampler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mpos_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeepFace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manchor_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg2_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'distance_matrix'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menforce_detection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mpos_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'facial_areas'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mpos_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'identity1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manchor_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pie31\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\deepface\\DeepFace.py\u001b[0m in \u001b[0;36mverify\u001b[1;34m(img1_path, img2_path, model_name, detector_backend, distance_metric, enforce_detection, align, normalization)\u001b[0m\n\u001b[0;32m    176\u001b[0m             )\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             img2_embedding_obj = represent(\n\u001b[0m\u001b[0;32m    179\u001b[0m                 \u001b[0mimg_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg2_content\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m                 \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pie31\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\deepface\\DeepFace.py\u001b[0m in \u001b[0;36mrepresent\u001b[1;34m(img_path, model_name, enforce_detection, detector_backend, align, normalization)\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"keras\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m             \u001b[1;31m# new tf versions show progress bar and it is annoying\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m             \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[1;31m# SFace and Dlib are not keras models and no verbose arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pie31\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pie31\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2348\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2349\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2350\u001b[1;33m                         \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2351\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2352\u001b[0m                             \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pie31\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pie31\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pie31\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 919\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    920\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mc:\\users\\pie31\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m       (concrete_function,\n\u001b[0;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pie31\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\pie31\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pie31\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "temp_pos_result = {\n",
    "    'verified': list(),\n",
    "    'distance': list(),\n",
    "    'threshold': list(),\n",
    "    'model': list(),\n",
    "    'detector_backend': list(),\n",
    "    'similarity_metric': list(),\n",
    "    'identity1': list(),\n",
    "    'identity2': list(),\n",
    "    'label': list(),\n",
    "    'time': list()\n",
    "}\n",
    "\n",
    "temp_pos_neg_result = {\n",
    "    'verified': list(),\n",
    "    'distance': list(),\n",
    "    'threshold': list(),\n",
    "    'model': list(),\n",
    "    'detector_backend': list(),\n",
    "    'similarity_metric': list(),\n",
    "    'identity1': list(),\n",
    "    'identity2': list(),\n",
    "    'label': list(),\n",
    "    'time': list()\n",
    "}\n",
    "\n",
    "fold_count = 0\n",
    "\n",
    "test_config = {\n",
    "    'skip_to_fold': 4,\n",
    "    'model_name': models[1],\n",
    "    'distance_matrix': metrics[2]\n",
    "}\n",
    "\n",
    "for fold, (train_idx, valid_idx) in tqdm(enumerate(k_fold.split(val_dataset)),total = split):\n",
    "    \n",
    "    valid_subsampler = torch.utils.data.Subset(val_dataset,valid_idx)\n",
    "\n",
    "    if fold+1 != test_config['skip_to_fold']:\n",
    "        print(f'skipping fold {fold+1}/{split}')\n",
    "        continue\n",
    "    print(f'starting fold {fold+1}/{split}')\n",
    "\n",
    "    for anchor_img, test_img, _, label, _, _ in tqdm(valid_subsampler):\n",
    "\n",
    "        pos_result = DeepFace.verify(img1_path = anchor_img, img2_path = test_img, model_name = test_config['model_name'], distance_metric = test_config['distance_matrix'], enforce_detection=False)\n",
    "        del pos_result['facial_areas']\n",
    "        pos_result['identity1'] = anchor_img.split('\\\\')[2]\n",
    "        pos_result['identity2'] = test_img.split('\\\\')[2]\n",
    "        pos_result['label'] = label\n",
    "        \n",
    "        for key in pos_result.keys():\n",
    "            temp_pos_result[str(key)].append(pos_result[str(key)])\n",
    "\n",
    "#     break\n",
    "\n",
    "pos_df = pd.DataFrame(temp_pos_result)\n",
    "# pos_neg_df = pd.DataFrame(temp_pos_neg_result)\n",
    "pos_df.to_csv('./'+test_config['model_name']+ str(test_config['skip_to_fold']) +'_5_fold.csv')\n",
    "# pos_neg_df.to_csv('./'+test_config['model_name']+'_true_neg'+ str(test_config['skip_to_fold']) +'_5_fold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos_neg_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19308/3655038385.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpos_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtest_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_pos_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'skip_to_fold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'_5_fold.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpos_neg_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtest_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_true_neg'\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'skip_to_fold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m'_5_fold.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pos_neg_df' is not defined"
     ]
    }
   ],
   "source": [
    "pos_df.to_csv('./'+test_config['model_name']+'_pos_' + str(test_config['skip_to_fold']) +'_5_fold.csv')\n",
    "pos_neg_df.to_csv('./'+test_config['model_name']+'_true_neg'+ str(test_config['skip_to_fold']) +'_5_fold.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
