{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Conv2d, BatchNorm1d, BatchNorm2d, PReLU, ReLU, ReLU6, Sigmoid, Dropout2d, Dropout, AvgPool2d, MaxPool2d, AdaptiveAvgPool2d, Sequential, Module, Parameter\n",
    "from statistics import mean\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 41\n",
    "# Define custom dataset\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, df, train, num_sample = None, transform = None, num_img_pool = 10, ):\n",
    "        # set random seed for FaceDataset\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        # create constructors\n",
    "        self.unique_img_name = None\n",
    "        self.train = train\n",
    "        self.data = dict()\n",
    "        self.images = list()\n",
    "        self.identities = list()\n",
    "        # label to indices\n",
    "        # self.label_to_indices = dict()\n",
    "        self.labels = list()\n",
    "        self.img_name = list()\n",
    "        # read csv file\n",
    "        self.df = df\n",
    "        # set the transformation\n",
    "        self.transform = transform\n",
    "        # drop last n row from dataframe\n",
    "        self.df = self.df.head(num_sample)\n",
    "        #get the length of entire dataset\n",
    "        self.len_ = len(self.df)\n",
    "        if num_sample is None or num_sample > self.len_:\n",
    "            num_sample = self.len_\n",
    "        # load imgs\n",
    "        self.load_imgs(self.df, num_imgs = num_img_pool, max = num_sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            anchor_img = self.images[idx]\n",
    "            anchor_label = self.labels[idx]\n",
    "            pos_idx = np.random.choice(np.arange(len(self.images))[self.labels == anchor_label])\n",
    "            neg_idx = np.random.choice(np.arange(len(self.images))[self.labels != anchor_label])\n",
    "\n",
    "            pos_img = self.images[pos_idx]\n",
    "            neg_img = self.images[neg_idx]\n",
    "\n",
    "            pos_label = self.labels[pos_idx]\n",
    "            neg_label = self.labels[neg_idx]\n",
    "\n",
    "            if self.transform is None:\n",
    "                img_to_tensor = transforms.ToTensor()\n",
    "                anchor_img = img_to_tensor(anchor_img)\n",
    "                pos_img = img_to_tensor(pos_img)\n",
    "                neg_img = img_to_tensor(neg_img)\n",
    "            else:\n",
    "                anchor_img = self.transform(anchor_img)\n",
    "                pos_img = self.transform(pos_img)\n",
    "                neg_img = self.transform(neg_img)\n",
    "            return anchor_img, pos_img, neg_img\n",
    "\n",
    "        else:\n",
    "            label = False\n",
    "            anchor_img = self.images[idx]\n",
    "            anchor_label = self.labels[idx]\n",
    "            if idx % 2 == 0:\n",
    "                test_idx = np.random.choice(np.arange(len(self.images))[self.labels == anchor_label])\n",
    "                label = True\n",
    "\n",
    "            else:\n",
    "                test_idx = np.random.choice(np.arange(len(self.images))[self.labels != anchor_label])\n",
    "\n",
    "            neg_idx = np.random.choice(np.arange(len(self.images))[self.labels != anchor_label])\n",
    "            test_img = self.images[test_idx]\n",
    "            neg_img = self.images[neg_idx]\n",
    "\n",
    "#             if self.transform is None:\n",
    "#                 img_to_tensor = transforms.ToTensor()\n",
    "#                 anchor_img = img_to_tensor(anchor_img)\n",
    "#                 test_img = img_to_tensor(test_img)\n",
    "#                 neg_img = img_to_tensor(neg_img)\n",
    "\n",
    "#             else:\n",
    "#                 anchor_img = self.transform(anchor_img)\n",
    "#                 test_img = self.transform(test_img)\n",
    "#                 neg_img = self.transform(neg_img)\n",
    "\n",
    "            return anchor_img, test_img, neg_img ,label, self.img_name[test_idx], self.identities[test_idx]\n",
    "\n",
    "    # load imgs from pandas to memory and define the maximum number of images\n",
    "    def load_imgs(self, df, num_imgs, max):\n",
    "        # iterate thought each row\n",
    "        for i, row in tqdm(df.iterrows(), total = max):\n",
    "            # get identity of each row\n",
    "            row_identity = row['identity']\n",
    "            # append each identity to numberical value\n",
    "            # self.label_to_indices[int(row_identity)] = i\n",
    "            count_img = 0\n",
    "            # loop imgs in each identity\n",
    "            for img_name in row['path']:\n",
    "                if count_img > num_imgs:\n",
    "                    break\n",
    "                # concatenate the directoru and image name\n",
    "                # path_to_image = self.dir+img_name\n",
    "                path_to_image = img_name\n",
    "                # open image and convert to RGB\n",
    "#                 img = Image.open(path_to_image).convert('RGB')\n",
    "                self.labels.append(i)\n",
    "                self.images.append(path_to_image)\n",
    "                \n",
    "                self.img_name.append(path_to_image)\n",
    "                self.identities.append(str(row_identity))\n",
    "                \n",
    "                count_img += 1  # print('Added img '+ str(row_identity))\n",
    "        self.labels = np.array(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[digiFace1M\\subjects_0-1999_72_imgs\\0\\20.png, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[digiFace1M\\subjects_0-1999_72_imgs\\1\\66.png, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[digiFace1M\\subjects_0-1999_72_imgs\\2\\29.png, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[digiFace1M\\subjects_0-1999_72_imgs\\3\\42.png, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[digiFace1M\\subjects_0-1999_72_imgs\\4\\33.png, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72661</th>\n",
       "      <td>199994</td>\n",
       "      <td>[digiFace1M\\subjects_166666-199998_5_imgs\\1999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72662</th>\n",
       "      <td>199995</td>\n",
       "      <td>[digiFace1M\\subjects_166666-199998_5_imgs\\1999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72663</th>\n",
       "      <td>199996</td>\n",
       "      <td>[digiFace1M\\subjects_166666-199998_5_imgs\\1999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72664</th>\n",
       "      <td>199997</td>\n",
       "      <td>[digiFace1M\\subjects_166666-199998_5_imgs\\1999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72665</th>\n",
       "      <td>199998</td>\n",
       "      <td>[digiFace1M\\subjects_166666-199998_5_imgs\\1999...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72666 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       identity                                               path\n",
       "0             0  [digiFace1M\\subjects_0-1999_72_imgs\\0\\20.png, ...\n",
       "1             1  [digiFace1M\\subjects_0-1999_72_imgs\\1\\66.png, ...\n",
       "2             2  [digiFace1M\\subjects_0-1999_72_imgs\\2\\29.png, ...\n",
       "3             3  [digiFace1M\\subjects_0-1999_72_imgs\\3\\42.png, ...\n",
       "4             4  [digiFace1M\\subjects_0-1999_72_imgs\\4\\33.png, ...\n",
       "...         ...                                                ...\n",
       "72661    199994  [digiFace1M\\subjects_166666-199998_5_imgs\\1999...\n",
       "72662    199995  [digiFace1M\\subjects_166666-199998_5_imgs\\1999...\n",
       "72663    199996  [digiFace1M\\subjects_166666-199998_5_imgs\\1999...\n",
       "72664    199997  [digiFace1M\\subjects_166666-199998_5_imgs\\1999...\n",
       "72665    199998  [digiFace1M\\subjects_166666-199998_5_imgs\\1999...\n",
       "\n",
       "[72666 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df = pd.read_csv('./digiface_csv_files/digi_all.csv')\n",
    "ds_df = ds_df.groupby('identity')['path'].apply(list).reset_index()\n",
    "ds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 50866\n",
      "Val Size: 13080\n",
      "Test Size: 8720\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26344</th>\n",
       "      <td>120344</td>\n",
       "      <td>[digiFace1M\\subjects_100000-133332_5_imgs\\1203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61833</th>\n",
       "      <td>189166</td>\n",
       "      <td>[digiFace1M\\subjects_166666-199998_5_imgs\\1891...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46921</th>\n",
       "      <td>174254</td>\n",
       "      <td>[digiFace1M\\subjects_166666-199998_5_imgs\\1742...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>8873</td>\n",
       "      <td>[digiFace1M\\subjects_8000-9999_72_imgs\\8873\\54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19875</th>\n",
       "      <td>113875</td>\n",
       "      <td>[digiFace1M\\subjects_100000-133332_5_imgs\\1138...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       identity                                               path\n",
       "26344    120344  [digiFace1M\\subjects_100000-133332_5_imgs\\1203...\n",
       "61833    189166  [digiFace1M\\subjects_166666-199998_5_imgs\\1891...\n",
       "46921    174254  [digiFace1M\\subjects_166666-199998_5_imgs\\1742...\n",
       "4873       8873  [digiFace1M\\subjects_8000-9999_72_imgs\\8873\\54...\n",
       "19875    113875  [digiFace1M\\subjects_100000-133332_5_imgs\\1138..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed = 41\n",
    "# splitting each dataset\n",
    "train_df, eval_df = train_test_split(ds_df, test_size= 0.3, shuffle = True, random_state = seed)\n",
    "val_df, test_df = train_test_split(eval_df, test_size = 0.4, shuffle = True, random_state = seed)\n",
    "\n",
    "# print to check size of each dataset\n",
    "print(f'Train Size: {len(train_df)}')\n",
    "print(f'Val Size: {len(val_df)}')\n",
    "print(f'Test Size: {len(test_df)}')\n",
    "\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8852d8802817452791749fa765307a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8720 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "split = 5\n",
    "k_fold = KFold(n_splits = split, shuffle = True, random_state=seed)\n",
    "\n",
    "val_dataset = FaceDataset(df = test_df, num_sample = 10000, train= False)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"cosine\", \"euclidean\", \"euclidean_l2\"]\n",
    "models = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"DeepID\", \"ArcFace\", \"Dlib\"]\n",
    "\n",
    "result = DeepFace.verify(img1_path = val_df[val_df['identity'] == 100992]['path'].item()[0], img2_path = val_df[val_df['identity'] == 100992]['path'].item()[1], model_name = models[1], distance_metric = metrics[2], enforce_detection=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verified': False,\n",
       " 'distance': 1.0183920954720027,\n",
       " 'threshold': 0.8,\n",
       " 'model': 'Facenet',\n",
       " 'detector_backend': 'opencv',\n",
       " 'similarity_metric': 'euclidean_l2',\n",
       " 'facial_areas': {'img1': {'x': 12, 'y': 17, 'w': 88, 'h': 88},\n",
       "  'img2': {'x': 6, 'y': 16, 'w': 78, 'h': 78}},\n",
       " 'time': 2.6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80a15ccf9fe4918aa1941ebad36185e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping fold 1/5\n",
      "skipping fold 2/5\n",
      "skipping fold 3/5\n",
      "skipping fold 4/5\n",
      "starting fold 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96d1438f0df4914a63e9429e9582627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_pos_result = {\n",
    "    'verified': list(),\n",
    "    'distance': list(),\n",
    "    'threshold': list(),\n",
    "    'model': list(),\n",
    "    'detector_backend': list(),\n",
    "    'similarity_metric': list(),\n",
    "    'identity1': list(),\n",
    "    'identity2': list(),\n",
    "    'label': list(),\n",
    "    'time': list()\n",
    "}\n",
    "\n",
    "temp_pos_neg_result = {\n",
    "    'verified': list(),\n",
    "    'distance': list(),\n",
    "    'threshold': list(),\n",
    "    'model': list(),\n",
    "    'detector_backend': list(),\n",
    "    'similarity_metric': list(),\n",
    "    'identity1': list(),\n",
    "    'identity2': list(),\n",
    "    'label': list(),\n",
    "    'time': list()\n",
    "}\n",
    "\n",
    "fold_count = 0\n",
    "\n",
    "test_config = {\n",
    "    'skip_to_fold': 5,\n",
    "    'model_name': models[2],\n",
    "    'distance_matrix': metrics[2]\n",
    "}\n",
    "\n",
    "for fold, (train_idx, valid_idx) in tqdm(enumerate(k_fold.split(val_dataset)),total = split):\n",
    "    \n",
    "    valid_subsampler = torch.utils.data.Subset(val_dataset,valid_idx)\n",
    "\n",
    "    if fold+1 != test_config['skip_to_fold']:\n",
    "        print(f'skipping fold {fold+1}/{split}')\n",
    "        continue\n",
    "    print(f'starting fold {fold+1}/{split}')\n",
    "\n",
    "    for anchor_img, test_img, _, label, _, _ in tqdm(valid_subsampler):\n",
    "\n",
    "        pos_result = DeepFace.verify(img1_path = anchor_img, img2_path = test_img, model_name = test_config['model_name'], distance_metric = test_config['distance_matrix'], enforce_detection=False)\n",
    "        del pos_result['facial_areas']\n",
    "        pos_result['identity1'] = anchor_img.split('\\\\')[2]\n",
    "        pos_result['identity2'] = test_img.split('\\\\')[2]\n",
    "        pos_result['label'] = label\n",
    "        \n",
    "        for key in pos_result.keys():\n",
    "            temp_pos_result[str(key)].append(pos_result[str(key)])\n",
    "\n",
    "#     break\n",
    "\n",
    "pos_df = pd.DataFrame(temp_pos_result)\n",
    "# pos_neg_df = pd.DataFrame(temp_pos_neg_result)\n",
    "pos_df.to_csv('./'+test_config['model_name']+ str(test_config['skip_to_fold']) +'_5_fold.csv')\n",
    "# pos_neg_df.to_csv('./'+test_config['model_name']+'_true_neg'+ str(test_config['skip_to_fold']) +'_5_fold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verified</th>\n",
       "      <th>distance</th>\n",
       "      <th>threshold</th>\n",
       "      <th>model</th>\n",
       "      <th>detector_backend</th>\n",
       "      <th>similarity_metric</th>\n",
       "      <th>identity1</th>\n",
       "      <th>identity2</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.04</td>\n",
       "      <td>Facenet512</td>\n",
       "      <td>opencv</td>\n",
       "      <td>euclidean_l2</td>\n",
       "      <td>183664</td>\n",
       "      <td>183664</td>\n",
       "      <td>True</td>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1.322133</td>\n",
       "      <td>1.04</td>\n",
       "      <td>Facenet512</td>\n",
       "      <td>opencv</td>\n",
       "      <td>euclidean_l2</td>\n",
       "      <td>183664</td>\n",
       "      <td>175846</td>\n",
       "      <td>False</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.877389</td>\n",
       "      <td>1.04</td>\n",
       "      <td>Facenet512</td>\n",
       "      <td>opencv</td>\n",
       "      <td>euclidean_l2</td>\n",
       "      <td>100589</td>\n",
       "      <td>100589</td>\n",
       "      <td>True</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0.788606</td>\n",
       "      <td>1.04</td>\n",
       "      <td>Facenet512</td>\n",
       "      <td>opencv</td>\n",
       "      <td>euclidean_l2</td>\n",
       "      <td>121502</td>\n",
       "      <td>121502</td>\n",
       "      <td>True</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.04</td>\n",
       "      <td>Facenet512</td>\n",
       "      <td>opencv</td>\n",
       "      <td>euclidean_l2</td>\n",
       "      <td>121502</td>\n",
       "      <td>121502</td>\n",
       "      <td>True</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>False</td>\n",
       "      <td>1.110126</td>\n",
       "      <td>1.04</td>\n",
       "      <td>Facenet512</td>\n",
       "      <td>opencv</td>\n",
       "      <td>euclidean_l2</td>\n",
       "      <td>5751</td>\n",
       "      <td>175989</td>\n",
       "      <td>False</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>False</td>\n",
       "      <td>1.195264</td>\n",
       "      <td>1.04</td>\n",
       "      <td>Facenet512</td>\n",
       "      <td>opencv</td>\n",
       "      <td>euclidean_l2</td>\n",
       "      <td>5751</td>\n",
       "      <td>196589</td>\n",
       "      <td>False</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>False</td>\n",
       "      <td>1.124571</td>\n",
       "      <td>1.04</td>\n",
       "      <td>Facenet512</td>\n",
       "      <td>opencv</td>\n",
       "      <td>euclidean_l2</td>\n",
       "      <td>105906</td>\n",
       "      <td>105906</td>\n",
       "      <td>True</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>False</td>\n",
       "      <td>1.133729</td>\n",
       "      <td>1.04</td>\n",
       "      <td>Facenet512</td>\n",
       "      <td>opencv</td>\n",
       "      <td>euclidean_l2</td>\n",
       "      <td>105182</td>\n",
       "      <td>195936</td>\n",
       "      <td>False</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>False</td>\n",
       "      <td>1.457318</td>\n",
       "      <td>1.04</td>\n",
       "      <td>Facenet512</td>\n",
       "      <td>opencv</td>\n",
       "      <td>euclidean_l2</td>\n",
       "      <td>187489</td>\n",
       "      <td>116277</td>\n",
       "      <td>False</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1744 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      verified  distance  threshold       model detector_backend  \\\n",
       "0         True  0.000000       1.04  Facenet512           opencv   \n",
       "1        False  1.322133       1.04  Facenet512           opencv   \n",
       "2         True  0.877389       1.04  Facenet512           opencv   \n",
       "3         True  0.788606       1.04  Facenet512           opencv   \n",
       "4         True  0.000000       1.04  Facenet512           opencv   \n",
       "...        ...       ...        ...         ...              ...   \n",
       "1739     False  1.110126       1.04  Facenet512           opencv   \n",
       "1740     False  1.195264       1.04  Facenet512           opencv   \n",
       "1741     False  1.124571       1.04  Facenet512           opencv   \n",
       "1742     False  1.133729       1.04  Facenet512           opencv   \n",
       "1743     False  1.457318       1.04  Facenet512           opencv   \n",
       "\n",
       "     similarity_metric identity1 identity2  label  time  \n",
       "0         euclidean_l2    183664    183664   True  4.14  \n",
       "1         euclidean_l2    183664    175846  False  0.21  \n",
       "2         euclidean_l2    100589    100589   True  0.20  \n",
       "3         euclidean_l2    121502    121502   True  0.22  \n",
       "4         euclidean_l2    121502    121502   True  0.21  \n",
       "...                ...       ...       ...    ...   ...  \n",
       "1739      euclidean_l2      5751    175989  False  0.25  \n",
       "1740      euclidean_l2      5751    196589  False  0.25  \n",
       "1741      euclidean_l2    105906    105906   True  0.26  \n",
       "1742      euclidean_l2    105182    195936  False  0.24  \n",
       "1743      euclidean_l2    187489    116277  False  0.25  \n",
       "\n",
       "[1744 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
